{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def BackgroundRemoval(cap, fgbg_params):\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN(**fgbg_params)\n",
    "\n",
    "    while(1):\n",
    "        # Take each frame\n",
    "        ret, frame = cap.read()\n",
    "        mask = fgbg.apply(frame)\n",
    "\n",
    "        # Bitwise-AND mask and original image\n",
    "        frame = cv2.bitwise_and(frame, frame, mask= mask)\n",
    "\n",
    "        #cv2.imshow('frame',frame)\n",
    "        #cv2.imshow('mask',mask)\n",
    "        cv2.imshow('res',frame)\n",
    "\n",
    "        #press 'q' to kill\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return \n",
    "\n",
    "# params for Background Removal\n",
    "fgbg_params = dict( history=1000, \n",
    "                    dist2Threshold=1000, \n",
    "                    detectShadows=False )\n",
    "\n",
    "cap = cv2.VideoCapture('Stereo_conveyor_without_occlusions.mp4')\n",
    "\n",
    "BackgroundRemoval(cap, fgbg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "def BackgroundRemoval(cap, fgbg_params):\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN(**fgbg_params)\n",
    "    \n",
    "    while(1):\n",
    "        # Take each frame\n",
    "        ret, originalFrame = cap.read()\n",
    "        \n",
    "        if ret == False:\n",
    "            break\n",
    "        \n",
    "        mask = fgbg.apply(originalFrame)\n",
    "        \n",
    "        kernel = np.ones((5,5), np.uint8) \n",
    "        \n",
    "        mask = cv2.erode(mask, kernel, iterations=1) \n",
    "        mask = cv2.dilate(mask, kernel, iterations=1) \n",
    "\n",
    "        # Bitwise-AND mask and original image\n",
    "        frame = cv2.bitwise_and(originalFrame, originalFrame, mask= mask)\n",
    "        \n",
    "        cropTop = 200\n",
    "        cropBottom = 600\n",
    "        cropLeft = 300\n",
    "        cropRight = 1170\n",
    "        cropped = mask[200:600, 300:1170]\n",
    "        \n",
    "        cnts, _ = cv2.findContours(cropped.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        #only proceed if at least one contour was found\n",
    "        if len(cnts) > 0:\n",
    "            # find the largest contour in the mask, then use\n",
    "            # it to compute the minimum enclosing circle and\n",
    "            # centroid\n",
    "            c = max(cnts, key=cv2.contourArea)\n",
    "            ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "            M = cv2.moments(c)\n",
    "            if M[\"m00\"] == 0.0:\n",
    "                continue\n",
    "            center = (int(M[\"m10\"] / M[\"m00\"])+cropLeft, int(M[\"m01\"] / M[\"m00\"])+cropTop)\n",
    "            \n",
    "            # only proceed if the radius meets a minimum size\n",
    "            if radius > 20 and radius < 200:\n",
    "                # draw the circle and centroid on the frame,\n",
    "                # then update the list of tracked points\n",
    "                cv2.circle(originalFrame, (int(x)+cropLeft, int(y)+cropTop), int(radius),\n",
    "                    (0, 255, 255), 2)\n",
    "                cv2.circle(originalFrame, center, 5, (0, 0, 255), -1)\n",
    "                \n",
    "            text = \"Object found at:\"\n",
    "            colour = (0, 255, 0)\n",
    "            cv2.putText(originalFrame,\"({}, {})\".format(center[0], center[1]), (0, 100), cv2.FONT_ITALIC, 1, colour)\n",
    "#             cv2.putText(originalFrame,\"Hello World!!!\", (0, 150), cv2.FONT_ITALIC, 2, colour)\n",
    "            \n",
    "        else: \n",
    "            text = \"Object not found\"\n",
    "            colour = (0, 0, 255)\n",
    "                \n",
    "        cv2.putText(originalFrame, text, (0, 50), cv2.FONT_ITALIC, 1, colour)\n",
    "\n",
    "\n",
    "        cv2.imshow('res',originalFrame)\n",
    "\n",
    "        #press 'q' to kill\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return \n",
    "\n",
    "# params for Background Removal\n",
    "fgbg_params = dict( history=1000, \n",
    "                    dist2Threshold=1000, \n",
    "                    detectShadows=False )\n",
    "\n",
    "cap = cv2.VideoCapture('Stereo_conveyor_without_occlusions.mp4')\n",
    "\n",
    "BackgroundRemoval(cap, fgbg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def BackgroundRemoval(cap, fgbg_params):\n",
    "    # Define kalman\n",
    "    kalman = cv2.KalmanFilter(4,2)\n",
    "    kalman.measurementMatrix = np.array([[1,0,0,0],\n",
    "                                         [0,1,0,0]],np.float32)\n",
    "    kalman.transitionMatrix = np.array([[1,0,1,0],\n",
    "                                        [0,1,0,1],\n",
    "                                        [0,0,1,0],\n",
    "                                        [0,0,0,1]],np.float32)\n",
    "    kalman.processNoiseCov = np.array([[1,0,0,0],\n",
    "                                       [0,1,0,0],\n",
    "                                       [0,0,1,0],\n",
    "                                       [0,0,0,1]],np.float32) * 0.03\n",
    "    measurement = np.array((2,1), np.float32)\n",
    "    prediction = np.zeros((2,1), np.float32)\n",
    "    \n",
    "    # Background removal\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN(**fgbg_params)\n",
    "    \n",
    "    # Define parameters to check it is new object?\n",
    "    thresholdCenter = 10\n",
    "    prevCenter = (0, 0)\n",
    "    prevRadius = 0\n",
    "    thresholdRadius = 5\n",
    "    \n",
    "    while(1):\n",
    "        # Take each frame\n",
    "        ret, originalFrame = cap.read()\n",
    "        \n",
    "        # Make a prediction\n",
    "        prediction = kalman.predict()\n",
    "        \n",
    "        if ret == False:\n",
    "            break\n",
    "        \n",
    "        # Get the mask of the object\n",
    "        mask = fgbg.apply(originalFrame)\n",
    "        \n",
    "        # Erode it and dilate it to avoid small points\n",
    "        kernel = np.ones((5,5), np.uint8) \n",
    "        mask = cv2.erode(mask, kernel, iterations=1) \n",
    "        mask = cv2.dilate(mask, kernel, iterations=1) \n",
    "\n",
    "        # Bitwise-AND mask and original image\n",
    "        frame = cv2.bitwise_and(originalFrame, originalFrame, mask= mask)\n",
    "        \n",
    "        # Make a crop to focus in the moving thing\n",
    "        cropTop = 200\n",
    "        cropBottom = 600\n",
    "        cropLeft = 300\n",
    "        cropRight = 1150\n",
    "        cropped = mask[cropTop:cropBottom, cropLeft:cropRight]\n",
    "        \n",
    "        # Find contours\n",
    "        cnts, _ = cv2.findContours(cropped.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Only proceed if at least one contour was found\n",
    "        if len(cnts) > 0:\n",
    "            # find the largest contour in the mask, then use\n",
    "            # it to compute the minimum enclosing circle and\n",
    "            # centroid\n",
    "            c = max(cnts, key=cv2.contourArea)\n",
    "            ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "            M = cv2.moments(c)\n",
    "            if M[\"m00\"] == 0.0:\n",
    "                continue\n",
    "            center = (int(M[\"m10\"] / M[\"m00\"])+cropLeft, int(M[\"m01\"] / M[\"m00\"])+cropTop)\n",
    "            \n",
    "            # only proceed if the radius meets a minimum size\n",
    "            if radius > 20 and radius < 200 and radius + thresholdRadius >= prevRadius:\n",
    "                # draw the circle and centroid on the frame,\n",
    "                # then update the list of tracked points\n",
    "                cv2.circle(originalFrame, (int(x)+cropLeft, int(y)+cropTop), int(radius),\n",
    "                    (0, 255, 255), 2)\n",
    "                cv2.circle(originalFrame, center, 5, (0, 0, 255), -1)\n",
    "                    \n",
    "                # Correct kalman \n",
    "                kalman.correct(np.array([np.float32(center[0]), np.float32(center[1])], np.float32))\n",
    "                \n",
    "                prevRadius = radius\n",
    "                text = \"Object found at:\"\n",
    "                colour = (0, 255, 0)\n",
    "                cv2.putText(originalFrame,\"({}, {})\".format(center[0], center[1]), (0, 100), cv2.FONT_ITALIC, 1, colour)\n",
    "\n",
    "#                 h, w, channels = originalFrame.shape\n",
    "#                 h = radius\n",
    "#                 w = radius\n",
    "\n",
    "                if (center[0] > prevCenter[0] + thresholdCenter) and (center[1] < prevCenter[1] - thresholdCenter):\n",
    "                    # New object\n",
    "                    print(\"New object!\")\n",
    "                    objectFound = False\n",
    "                    prevRadius = 0\n",
    "                prevCenter = center\n",
    "            else:\n",
    "                # Object not found\n",
    "                text = \"Object not found\"\n",
    "                objectFound = False\n",
    "                colour = (0, 0, 255)\n",
    "                \n",
    "        \n",
    "        #\n",
    "        else: \n",
    "            # Object not found\n",
    "            text = \"Object not found\"\n",
    "            objectFound = False\n",
    "            colour = (0, 0, 255)\n",
    "            prevRadius = 0\n",
    "            \n",
    "        prediction = kalman.predict()\n",
    "#         originalFrame = cv2.rectangle(originalFrame, (prediction[0]-(0.5*w), prediction[1]-(0.5*h)), \n",
    "#                                 (prediction[0]+(0.5*w), prediction[1]+(0.5*h)), (0,255,0),2)\n",
    "        cv2.circle(originalFrame, (prediction[0]+prediction[2], prediction[1]+prediction[3]), 5, (255, 0, 0), -1)\n",
    "        cv2.putText(originalFrame,\"({}, {}, {}, {})\".format(prediction[0], prediction[1], prediction[2], prediction[3]), \n",
    "                    (0, 150), cv2.FONT_ITALIC, 1, colour)\n",
    "    \n",
    "            \n",
    "        cv2.putText(originalFrame, text, (0, 50), cv2.FONT_ITALIC, 1, colour)\n",
    "\n",
    "\n",
    "        cv2.imshow('res',originalFrame)\n",
    "\n",
    "        #press 'q' to kill\n",
    "        if cv2.waitKey(15) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return \n",
    "\n",
    "# params for Background Removal\n",
    "fgbg_params = dict( history=1000, \n",
    "                    dist2Threshold=1000, \n",
    "                    detectShadows=False )\n",
    "\n",
    "cap = cv2.VideoCapture('Stereo_conveyor_with_occlusions.mp4')\n",
    "\n",
    "BackgroundRemoval(cap, fgbg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection import VideoObjectDetection\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "camera = cv2.VideoCapture(0) \n",
    "\n",
    "detector = VideoObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(os.path.join(execution_path , \"yolo.h5\"))\n",
    "detector.loadModel()\n",
    "\n",
    "video_path = detector.detectObjectsFromVideo(camera_input=camera,\n",
    "                                output_file_path=os.path.join(execution_path, \"camera_detected_1\")\n",
    "                                , frames_per_second=29, log_progress=True)\n",
    "print(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection import VideoObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = VideoObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath( os.path.join(execution_path , \"yolo.h5\"))\n",
    "detector.loadModel()\n",
    "\n",
    "video_path = detector.detectObjectsFromVideo(input_file_path=os.path.join( execution_path, \"Stereo_conveyor_without_occlusions.mp4\"),\n",
    "                                output_file_path=os.path.join(execution_path, \"traffic_mini_detected_1\")\n",
    "                                , frames_per_second=29, log_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking with depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sum_abs_diff(image1, image2):\n",
    "    image1 = image1.astype('int32')\n",
    "    image2 = image2.astype('int32')\n",
    "    \n",
    "    sad = 0\n",
    "    \n",
    "    if image1.shape == image2.shape:\n",
    "        diff = image1 - image2\n",
    "        sad = np.sum(np.absolute(diff))\n",
    "    else:\n",
    "        sad = -1\n",
    "    \n",
    "    return sad\n",
    "\n",
    "def scan_line(span, template, search_col_min, search_col_max):\n",
    "    min_place = -1\n",
    "    min_value = float('inf')\n",
    "    for i in range(search_col_min, search_col_max):\n",
    "        diff = sum_abs_diff(span[:, i:i + span.shape[0]], template)\n",
    "        if diff < min_value:\n",
    "            min_value = diff\n",
    "            min_place = i\n",
    "    return (min_place, min_value)\n",
    "\n",
    "def Depth(leftGrayImg, rightGrayImg, positionOnLeft, halfWindow):\n",
    "    baseline = 120\n",
    "    focalLength = 700\n",
    "    \n",
    "    template = leftGrayImg[positionOnLeft[1]-halfWindow:positionOnLeft[1]+halfWindow,\\\n",
    "                           positionOnLeft[0]-halfWindow:positionOnLeft[0]+halfWindow]    \n",
    "    span = rightGrayImg[positionOnLeft[1]-halfWindow:positionOnLeft[1]+halfWindow, :]\n",
    "    min_place, min_value = scan_line(span, template, positionOnLeft[0]-250, positionOnLeft[0]-50-halfWindow)\n",
    "    \n",
    "    if min_place < 0:\n",
    "        print('fail')\n",
    "        \n",
    "    disparity = positionOnLeft[0]-min_place\n",
    "    #print(f\"Disparity: {disparity} pixels\")\n",
    "    \n",
    "    depth = focalLength*baseline/disparity\n",
    "    #print(f\"Depth of pixel [{positionOnLeft[0]},{positionOnLeft[1]}] in mm: {depth}\")\n",
    "    return depth\n",
    "\n",
    "def BackgroundRemoval(rightImages):\n",
    "    # Define kalman\n",
    "#     alpha = 1/500\n",
    "#     kalman = cv2.KalmanFilter(6,3)\n",
    "#     kalman.measurementMatrix = np.array([[1,0,0,0,0,0],\n",
    "#                                          [0,0,1,0,0,0],\n",
    "#                                          [0,0,0,0,1,0]], np.float32)\n",
    "#     kalman.transitionMatrix = np.array([[1,1,0,0,0,0],\n",
    "#                                         [0,1,0,0,0,-0.86*alpha],\n",
    "#                                         [0,0,1,1,0,0],\n",
    "#                                         [0,0,0,1,0,0.5*alpha],\n",
    "#                                         [0,0,0,0,1,1],\n",
    "#                                         [0,0,0,0,0,1]], np.float32)\n",
    "#     kalman.processNoiseCov = np.eye(6, dtype=np.float32) * 0.03\n",
    "#     kalman.measurementNoiseCov = np.eye(3, dtype=np.float32) * 0.06\n",
    "#     measurement = np.array((3,1), np.float32)\n",
    "#     prediction = np.zeros((6,1), np.float32)\n",
    "    \n",
    "    kalman = cv2.KalmanFilter(6,2)\n",
    "    kalman.measurementMatrix = np.array([[1,0,0,0,0,0],\n",
    "                                         [0,0,0,1,0,0]], np.float32)\n",
    "    kalman.transitionMatrix = np.array([[1,1,0.5,0,0,0],\n",
    "                                        [0,1,1,0,0,0],\n",
    "                                        [0,0,1,0,0,0],\n",
    "                                        [0,0,0,1,1,0.5],\n",
    "                                        [0,0,0,0,1,1],\n",
    "                                        [0,0,0,0,0,1]], np.float32)\n",
    "    kalman.processNoiseCov = np.array([[0.01,0,0,0,0,0],\n",
    "                                       [0,0.5,0,0,0,0],\n",
    "                                       [0,0,5,0,0,0],\n",
    "                                       [0,0,0,0.01,0,0],\n",
    "                                       [0,0,0,0,0.5,0],\n",
    "                                       [0,0,0,0,0,5]], np.float32)\n",
    "    kalman.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.03\n",
    "    measurement = np.array((2,1), np.float32)\n",
    "    prediction = np.zeros((6,1), np.float32)\n",
    "    \n",
    "#     N = 5\n",
    "#     cumsum, movingAvg = [0], []\n",
    "#     i = 0\n",
    "    \n",
    "    # Background removal\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN(history=1000, dist2Threshold=1000, detectShadows=False)\n",
    "    \n",
    "    # Define parameters to check it is new object?\n",
    "    thresholdCenter = 500\n",
    "    prevCenter = (0, 0)\n",
    "    prevArea = 0\n",
    "    prevRadius = 0\n",
    "    thresholdRadius = 5\n",
    "    thresholdArea = 2500\n",
    "    \n",
    "    objectFound = False\n",
    "    objectStartArea = 0\n",
    "    \n",
    "    dismissFrames = 20\n",
    "    counter = 0\n",
    "    rightImages[250:] = []\n",
    "    \n",
    "    for rightName in rightImages:\n",
    "        counter += 1\n",
    "        leftName = rightName.replace('right','left').replace('Right','Left')\n",
    "        \n",
    "        # Read left frame to get object detection running\n",
    "        originalFrame = cv2.imread(rightName)\n",
    "        rightGray = cv2.cvtColor(originalFrame, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "        # Make a prediction\n",
    "        prediction = kalman.predict()\n",
    "        \n",
    "        # Get the mask of the object\n",
    "        mask = fgbg.apply(originalFrame)\n",
    "        \n",
    "        # Erode it and dilate it to avoid small points\n",
    "        kernel = np.ones((5,5), np.uint8) \n",
    "        mask = cv2.erode(mask, kernel, iterations=1) \n",
    "        mask = cv2.dilate(mask, kernel, iterations=1) \n",
    "\n",
    "        # Bitwise-AND mask and original image\n",
    "        frame = cv2.bitwise_and(originalFrame, originalFrame, mask=mask)\n",
    "        \n",
    "        # Make a crop to focus in the moving thing\n",
    "        cropTop = 200\n",
    "        cropBottom = 675\n",
    "        cropLeft = 200\n",
    "        cropRight = 1200\n",
    "        cropped = mask[cropTop:cropBottom, cropLeft:cropRight]\n",
    "        \n",
    "        if counter > dismissFrames:\n",
    "            # Find contours\n",
    "            cnts, _ = cv2.findContours(cropped.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Only proceed if at least one contour was found\n",
    "            if len(cnts) > 0:\n",
    "                # find the largest contour in the mask, then use\n",
    "                # it to compute the minimum enclosing circle and\n",
    "                # centroid\n",
    "                c = max(cnts, key=cv2.contourArea)\n",
    "                area = cv2.contourArea(c)\n",
    "#                 cumsum.append(cumsum[-1] + area)\n",
    "#                 i += 1\n",
    "#                 if i >= N:\n",
    "#                     movingAvg.append((cumsum[i] - cumsum[i-N])/N)\n",
    "                #((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "                x1,x2,x3,x4 = cv2.boundingRect(c)\n",
    "                #print(rect)\n",
    "                cv2.rectangle(originalFrame, (x1+cropLeft,x2+cropTop,x3,x4), (0, 255, 255))\n",
    "                M = cv2.moments(c)\n",
    "                if M[\"m00\"] == 0.0:\n",
    "                    prediction = kalman.predict()\n",
    "                    continue\n",
    "                center = (int(M[\"m10\"] / M[\"m00\"])+cropLeft, int(M[\"m01\"] / M[\"m00\"])+cropTop)            \n",
    "\n",
    "                if area > thresholdArea:\n",
    "                    # NEW OBJECT ON THE CONVEYOR\n",
    "                    if center[0] > prevCenter[0] + thresholdCenter:\n",
    "                        kalman = cv2.KalmanFilter(6,2)\n",
    "                        kalman.measurementMatrix = np.array([[1,0,0,0,0,0],\n",
    "                                                             [0,0,0,1,0,0]], np.float32)\n",
    "                        kalman.transitionMatrix = np.array([[1,1,0.5,0,0,0],\n",
    "                                                            [0,1,1,0,0,0],\n",
    "                                                            [0,0,1,0,0,0],\n",
    "                                                            [0,0,0,1,1,0.5],\n",
    "                                                            [0,0,0,0,1,1],\n",
    "                                                            [0,0,0,0,0,1]], np.float32)\n",
    "                        kalman.processNoiseCov = np.eye(6, dtype=np.float32) * 0.03\n",
    "                        kalman.processNoiseCov = np.array([[0.01,0,0,0,0,0],\n",
    "                                                           [0,0.5,0,0,0,0],\n",
    "                                                           [0,0,5,0,0,0],\n",
    "                                                           [0,0,0,0.01,0,0],\n",
    "                                                           [0,0,0,0,0.5,0],\n",
    "                                                           [0,0,0,0,0,5]], np.float32)\n",
    "                        kalman.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.03\n",
    "                        print(\"New object!\")\n",
    "                        objectStartArea = area\n",
    "                        prevArea = area\n",
    "\n",
    "                    # MEASUREMENT UPDATE OF THE KALMAN FILTER\n",
    "                    if area > area > objectStartArea * 0.85 and area > prevArea * 0.95:\n",
    "                        cv2.circle(originalFrame, center, 5, (0, 255, 255), -1)\n",
    "                        #cv2.circle(originalFrame, center, 5, (0, 0, 255), -1)\n",
    "\n",
    "                        left = cv2.imread(leftName)\n",
    "                        leftGray = cv2.cvtColor(left, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                        depth = Depth(leftGray, rightGray, center, 50)\n",
    "                        cv2.putText(originalFrame, f\"Depth: {depth:.2f} mm\", (0,200), cv2.FONT_ITALIC, 1, (0,0,0))\n",
    "\n",
    "                        # Correct kalman \n",
    "                        kalman.correct(np.array([np.float32(center[0]), np.float32(center[1])], np.float32))\n",
    "\n",
    "                        prevArea = area\n",
    "                        text = \"Object found at:\"\n",
    "                        objectFound = True\n",
    "                        colour = (0, 255, 0)\n",
    "                        cv2.putText(originalFrame, f\"({center[0]}, {center[1]})\", (0, 100), cv2.FONT_ITALIC, 1, colour)\n",
    "\n",
    "                        prevCenter = center\n",
    "                    else:\n",
    "                        # Object not found\n",
    "                        text = \"Object not found\"\n",
    "                        objectFound = False\n",
    "                        colour = (0, 0, 255)\n",
    "            else: \n",
    "                # Object not found\n",
    "                text = \"Object not found\"\n",
    "                objectFound = False\n",
    "                colour = (0, 0, 255)\n",
    "                prevArea = 0\n",
    "#                 cumsum.append(cumsum[-1])\n",
    "#                 i += 1\n",
    "#                 if i >= N:\n",
    "#                     movingAvg.append((cumsum[i] - cumsum[i-N])/N)\n",
    "\n",
    "            #prediction = kalman.predict()\n",
    "    #         originalFrame = cv2.rectangle(originalFrame, (prediction[0]-(0.5*w), prediction[1]-(0.5*h)), \n",
    "    #                                 (prediction[0]+(0.5*w), prediction[1]+(0.5*h)), (0,255,0),2)\n",
    "#             cv2.circle(originalFrame, (prediction[0]+prediction[1]+0.5*prediction[2], \n",
    "#                                        prediction[3]+prediction[4]+0.5*prediction[5]), \n",
    "#                                        5, (255, 0, 0), -1)\n",
    "            cv2.circle(originalFrame, (prediction[0], prediction[3]), 5, (255, 0, 0), -1)\n",
    "            cv2.putText(originalFrame, f\"(X:{prediction[0]}, Y:{prediction[3]}\",\n",
    "                        (0, 150), cv2.FONT_ITALIC, 1, colour)\n",
    "\n",
    "            cv2.putText(originalFrame, text, (0, 50), cv2.FONT_ITALIC, 1, colour)\n",
    "\n",
    "            cv2.imshow('res', originalFrame)\n",
    "\n",
    "#             print(prevArea)\n",
    "#             print(objectStartArea)\n",
    "\n",
    "        #press 'q' to kill\n",
    "        if cv2.waitKey(15) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return \n",
    "\n",
    "rightImages = glob.glob('undistortedImagesWithOcclusion/right/*.png')\n",
    "assert rightImages\n",
    "\n",
    "BackgroundRemoval(rightImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Version for Video (May 10, 9:30pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New object!\n",
      "New object!\n",
      "New object!\n",
      "New object!\n",
      "New object!\n",
      "New object!\n",
      "New object!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def sum_abs_diff(image1, image2):\n",
    "    image1 = image1.astype('int32')\n",
    "    image2 = image2.astype('int32')\n",
    "    \n",
    "    sad = 0\n",
    "    \n",
    "    if image1.shape == image2.shape:\n",
    "        diff = image1 - image2\n",
    "        sad = np.sum(np.absolute(diff))\n",
    "    else:\n",
    "        sad = -1\n",
    "    \n",
    "    return sad\n",
    "\n",
    "def scan_line(span, template, search_col_min, search_col_max):\n",
    "    min_place = -1\n",
    "    min_value = float('inf')\n",
    "    if search_col_min >= search_col_max:\n",
    "        return (False, 0)\n",
    "    for i in range(search_col_min, search_col_max):\n",
    "        diff = sum_abs_diff(span[:, i:i + span.shape[0]], template)\n",
    "        if diff < min_value:\n",
    "            min_value = diff\n",
    "            min_place = i\n",
    "    return (min_place, min_value)\n",
    "\n",
    "def Depth(leftGrayImg, rightGrayImg, positionOnRight, halfWindow):\n",
    "    baseline = 120\n",
    "    focalLength = 700\n",
    "    \n",
    "    template = rightGrayImg[positionOnRight[0]-halfWindow:positionOnRight[0]+halfWindow,\\\n",
    "                           positionOnRight[1]:positionOnRight[1]+halfWindow*2]\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.imshow(template)\n",
    "        \n",
    "    span = leftGrayImg[positionOnRight[0]-halfWindow:positionOnRight[0]+halfWindow, :]\n",
    "#     plt.figure()\n",
    "    \n",
    "    min_place, min_value = scan_line(span, template, positionOnRight[1]+halfWindow,\n",
    "                                     min(positionOnRight[1]+250, leftGrayImg.shape[1] - 2*halfWindow))\n",
    "#     plt.imshow(span)\n",
    "    if min_place < 0:\n",
    "        return 0;\n",
    "        \n",
    "    disparity = min_place - positionOnRight[1]\n",
    "#     print(f\"Disparity: {disparity} pixels\")\n",
    "    \n",
    "    depth = focalLength*baseline/disparity\n",
    "#     print(f\"Depth of pixel [{positionOnRight[0]},{positionOnRight[1]}] in mm: {depth}\")\n",
    "    return depth\n",
    "\n",
    "def BackgroundRemoval(rightImages, occlusion):\n",
    "    out = cv2.VideoWriter('WithoutOcclusionFinal.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 10, (1280, 720))\n",
    "    \n",
    "    # Initialize Kalman filter\n",
    "    stateSize = 7\n",
    "    measSize = 5\n",
    "    contrSize = 0\n",
    "    kalman = cv2.KalmanFilter(stateSize, measSize, contrSize, cv2.CV_32F)\n",
    "    state = np.zeros((stateSize, 1), np.float32) # x,y,v_x,v_y,w,h,d,v_d\n",
    "    meas = np.zeros((measSize, 1), np.float32) # x,y,w,h,d\n",
    "    kalman.measurementMatrix = np.array([[1,0,0,0,0,0,0],\n",
    "                                         [0,1,0,0,0,0,0],\n",
    "                                         [0,0,0,0,1,0,0],\n",
    "                                         [0,0,0,0,0,1,0],\n",
    "                                         [0,0,0,0,0,0,1]], np.float32)\n",
    "    kalman.transitionMatrix = np.array([[1,0,1,0,0,0,0],\n",
    "                                        [0,1,0,1,0,0,0],\n",
    "                                        [0,0,1,0,0,0,0],\n",
    "                                        [0,0,0,1,0,0,0],\n",
    "                                        [0,0,0,0,1,0,0],\n",
    "                                        [0,0,0,0,0,1,0],\n",
    "                                        [0,0,0,0,0,0,1]], np.float32)\n",
    "    kalman.processNoiseCov = np.array([[0.01,0,0,0,0,0,0],\n",
    "                                       [0,0.01,0,0,0,0,0],\n",
    "                                       [0,0,5,0,0,0,0],\n",
    "                                       [0,0,0,5,0,0,0],\n",
    "                                       [0,0,0,0,0.01,0,0],\n",
    "                                       [0,0,0,0,0,0.01,0],\n",
    "                                       [0,0,0,0,0,0,0.1]], np.float32)\n",
    "    kalman.measurementNoiseCov = np.eye(measSize, dtype=np.float32) * 0.1\n",
    "    \n",
    "    # Filtering\n",
    "    fgbg = cv2.createBackgroundSubtractorKNN(history=1000, dist2Threshold=1000, detectShadows=False)  \n",
    "    # Define parameters to check it is new object?\n",
    "    thresholdCenter = 500\n",
    "    prevCenter = (0, 0)\n",
    "    prevArea = 0\n",
    "    thresholdArea = 2500\n",
    "\n",
    "    # Needed for the area calculation to work\n",
    "    dismissFrames = 20\n",
    "    counter = 0\n",
    "    \n",
    "    ratio = 0\n",
    "    ratioStart = 0\n",
    "    found = False\n",
    "    oCounter = 0\n",
    "    objectFound = False\n",
    "    afterOcclusion = False\n",
    "    prevWidth = 0\n",
    "    \n",
    "    for rightName in rightImages:\n",
    "        counter += 1\n",
    "        leftName = rightName.replace('right','left').replace('Right','Left')\n",
    "        \n",
    "        # Read left frame to get object detection running\n",
    "        originalFrame = cv2.imread(rightName)\n",
    "        frame = originalFrame.copy()\n",
    "        rightGray = cv2.cvtColor(originalFrame, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "        if found:\n",
    "            # Make a prediction\n",
    "            state = kalman.predict()\n",
    "            predRect = (state[0], state[1] - state[5]/2, state[4], state[5])\n",
    "            center = (state[0], state[1])\n",
    "            cv2.putText(originalFrame, f\"Predictions: x={state[0]}, y={state[1]}, depth={state[6]}\",\n",
    "                       (100,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0))\n",
    "            cv2.circle(originalFrame, center, 5, (255,0,0), -1)\n",
    "            cv2.rectangle(originalFrame, predRect, (255,0,0), 2)\n",
    "                \n",
    "        # Get the mask of the object\n",
    "        mask = fgbg.apply(frame)\n",
    "        \n",
    "        # Erode it and dilate it to avoid small points\n",
    "        kernel = np.ones((5,5), np.uint8) \n",
    "        mask = cv2.erode(mask, kernel, iterations=2) \n",
    "        mask = cv2.dilate(mask, kernel, iterations=2) \n",
    "\n",
    "        # Bitwise-AND mask and original image\n",
    "        frame = cv2.bitwise_and(originalFrame, originalFrame, mask=mask)\n",
    "        \n",
    "        # Make a crop to focus in the moving thing\n",
    "        cropTop = 200\n",
    "        cropBottom = 675\n",
    "        cropLeft = 0#200\n",
    "        cropRight = 1280#1150#1280\n",
    "        cropped = mask[cropTop:cropBottom, cropLeft:cropRight]\n",
    "        \n",
    "        if counter > dismissFrames:\n",
    "            cnts, _ = cv2.findContours(cropped.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "            if len(cnts) > 0:\n",
    "\n",
    "                c = max(cnts, key=cv2.contourArea)\n",
    "                area = cv2.contourArea(c)\n",
    "                \n",
    "                x,y,width,height = cv2.boundingRect(c)\n",
    "                cv2.rectangle(originalFrame, (x+cropLeft,y+cropTop,width,height), (0, 255, 0))\n",
    "                \n",
    "                M = cv2.moments(c)\n",
    "                if M[\"m00\"] == 0.0:\n",
    "                    continue\n",
    "                center = (int(M[\"m10\"] / M[\"m00\"]) + cropLeft, int(M[\"m01\"] / M[\"m00\"]) + cropTop)            \n",
    "\n",
    "                if area > thresholdArea:\n",
    "                    currentRatio = float(width)/float(height)\n",
    "                    # Check for new object\n",
    "                    if center[0] > prevCenter[0] + thresholdCenter:\n",
    "                        print(\"New object!\")\n",
    "                        afterOcclusion = False\n",
    "                        gettingBehindOcclusion = False\n",
    "                        found = False\n",
    "                        oCounter = 30\n",
    "                    # Check whether object reappeared on the left side of the occlusion\n",
    "                    elif center[0] < prevCenter[0] - 300:\n",
    "                        afterOcclusion = True\n",
    "                        \n",
    "                    left = cv2.imread(leftName)\n",
    "                    leftGray = cv2.cvtColor(left, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    meas[0] = x + cropLeft\n",
    "                    meas[1] = y + cropTop + height/2.0\n",
    "                    meas[2] = float(width)\n",
    "                    meas[3] = float(height)\n",
    "                    meas[4] = Depth(leftGray, rightGray, (int(meas[1]), int(meas[0])), 10)\n",
    "                    \n",
    "                    writeMeas = True\n",
    "\n",
    "                    # After occlusion\n",
    "                    if afterOcclusion:\n",
    "                        kalman.correct(meas)\n",
    "                    \n",
    "                    # Before occlusion\n",
    "                    elif oCounter > 0:\n",
    "                        writeMeas = True\n",
    "                        ratio = currentRatio\n",
    "                        oCounter -= 1\n",
    "                        if not found:\n",
    "                            kalman.errorCovPre = np.eye(stateSize, dtype=np.float32)\n",
    "                            state[0] = meas[0]\n",
    "                            state[1] = meas[1]\n",
    "                            state[2] = 0\n",
    "                            state[3] = 0\n",
    "                            state[4] = meas[2]\n",
    "                            state[5] = meas[3]\n",
    "                            state[6] = meas[4]\n",
    "                            kalman.statePost = state\n",
    "                            found = True\n",
    "                        else:\n",
    "                            kalman.correct(meas)\n",
    "                    elif occlusion:\n",
    "                        # Checking if occlusion started\n",
    "                        if abs(currentRatio-ratio) < 0.05 and not gettingBehindOcclusion:\n",
    "                            cv2.circle(originalFrame, (meas[0], meas[1]), 2, (0, 255, 0), -1)\n",
    "                            kalman.correct(meas)\n",
    "\n",
    "                        # Otherwise, the object is getting behind the occlusion\n",
    "                        else:\n",
    "                            gettingBehindOcclusion = True\n",
    "                            writeMeas = False\n",
    "                    else:\n",
    "                        cv2.circle(originalFrame, (meas[0], meas[1]), 2, (0, 255, 0), -1)\n",
    "                        kalman.correct(meas)\n",
    "\n",
    "                    prevCenter = center\n",
    "                    if writeMeas:\n",
    "                        cv2.putText(originalFrame, f\"Measurement: x={meas[0]}, y={meas[1]}, d={meas[4]}\",\n",
    "                                   (100,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0))\n",
    "                else:\n",
    "                    pass\n",
    "            else: \n",
    "                pass\n",
    "\n",
    "            cv2.imshow('res', originalFrame)\n",
    "            out.write(originalFrame)\n",
    "\n",
    "        #press 'q' to kill\n",
    "        if cv2.waitKey(15) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    out.release()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    return \n",
    "\n",
    "occlusion = not True\n",
    "if occlusion:\n",
    "    basename = 'undistortedImagesWithOcclusion/right/*.png'\n",
    "else:\n",
    "    basename = 'undistortedImagesWithoutOcclusion/right/*.png'\n",
    "\n",
    "rightImages = glob.glob(basename)\n",
    "assert rightImages\n",
    "\n",
    "BackgroundRemoval(rightImages, occlusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
